{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc933064-16d3-4247-81d9-d029f7ee94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The 'r' before the string tells Python to ignore the special meaning of backslashes\n",
    "expected_path = r'C:\\Users\\DELL\\.kaggle\\kaggle.json'\n",
    "\n",
    "if os.path.exists(expected_path):\n",
    "    print(\"Success! The key is in the right place.\")\n",
    "    import kaggle\n",
    "    # This command will now download the file since the key is found\n",
    "    get_ipython().system('kaggle datasets download ankitbansal06/retail-orders -f orders.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5db54-7c0f-46ce-871f-c7f88d6c0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset using  kaggle api\n",
    "!kaggle datasets download ankitbansal06/retail-orders -f orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03009017-02f8-4c48-8e76-87883fbc632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Force a clean download of the ZIP file\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = r'C:\\Users\\DELL\\.kaggle'\n",
    "get_ipython().system('kaggle datasets download ankitbansal06/retail-orders --force')\n",
    "\n",
    "# 2. Extract the actual CSV from the zip\n",
    "# The file downloaded will be named 'retail-orders.zip'\n",
    "with zipfile.ZipFile('retail-orders.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "# 3. Read the extracted file (which is now real text)\n",
    "df = pd.read_csv('orders.csv', na_values=['Not Available', 'unknown'])\n",
    "\n",
    "# 4. Clean the columns so they match the tutorial\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Now you will see the same table as the tutorial!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614fe7f-8c55-494e-bfb3-f7b8e2eacc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5813-af2d-4a4b-92d7-e24b17cdf1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns names ..make them lower case and replace space with underscore\n",
    "#df.rename(columns={'Order Id':'order_id', 'City':'city'})\n",
    "#df.columns=df.columns.str.lower()\n",
    "#df.columns=df.columns.str.replace(' ','_')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ba7cb-aa1a-401f-842f-d3f04aca83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate discount value first\n",
    "df['discount'] = df['list_price'] * df['discount_percent'] * 0.01\n",
    "\n",
    "# 2. Subtract discount from list price to get sale price\n",
    "df['sale_price'] = df['list_price'] - df['discount']\n",
    "\n",
    "# 3. Now that sale_price exists, we can calculate profit\n",
    "df['profit'] = df['sale_price'] - df['cost_price']\n",
    "\n",
    "# Show the results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd572a-a93f-45a5-b330-46b5bec89b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert order date from object data type  to datetime\n",
    "df['order_date']=pd.to_datetime(df['order_date'],format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c10812-fa3c-4588-8220-9fdec16157d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cost price list price and discount percent columns\n",
    "df.drop(columns=['list_price','cost_price','discount_percent'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b3442-4e4d-4d5b-8c12-d1a3fd667831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a691f1-6eca-4755-881a-d4a8da077d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c98c7f-80ff-44a5-a588-12f01330beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "import urllib.parse\n",
    "\n",
    "# 1. Database Credentials\n",
    "user = 'postgres'\n",
    "password = 'admin123' \n",
    "database = 'order_database' \n",
    "\n",
    "# 2. Handle special characters in password\n",
    "safe_password = urllib.parse.quote_plus(password)\n",
    "engine = sal.create_engine(f'postgresql://{user}:{safe_password}@localhost:5432/{database}')\n",
    "\n",
    "# 3. Load the Data\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # This will create a table named 'df_orders' automatically\n",
    "        df.to_sql('df_orders', con=conn, index=False, if_exists='replace')\n",
    "        print(\"Success! The orders.csv data is now in your PostgreSQL database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d19d3-767d-4824-b048-3dd597216799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "import urllib.parse\n",
    "\n",
    "# 1. Your verified credentials\n",
    "user = 'postgres'\n",
    "password = 'admin123' \n",
    "database = 'order_database' \n",
    "\n",
    "# 2. Establish Connection\n",
    "safe_password = urllib.parse.quote_plus(password)\n",
    "engine = sal.create_engine(f'postgresql://{user}:{safe_password}@localhost:5432/{database}')\n",
    "\n",
    "# 3. Load the orders.csv data\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # 'df' must be the variable where you loaded your orders.csv\n",
    "        df.to_sql('df_orders', con=conn, index=False, if_exists='replace')\n",
    "        print(\"Success! Your orders data is now in PostgreSQL.\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800c7db-f244-4f8d-82a0-1a55305b9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "import urllib.parse\n",
    "\n",
    "# 1. Credentials\n",
    "user = 'postgres'\n",
    "password = 'admin123' \n",
    "database = 'order_database' \n",
    "\n",
    "# 2. Re-establish the Engine\n",
    "safe_password = urllib.parse.quote_plus(password)\n",
    "engine = sal.create_engine(f'postgresql://{user}:{safe_password}@localhost:5432/{database}')\n",
    "\n",
    "# 3. Use 'with' to automatically handle the connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # Change 'append' to 'replace' if the table doesn't exist yet\n",
    "        # Use 'append' only if you are adding new data to an existing table\n",
    "        df.to_sql('df_orders', con=conn, index=False, if_exists='append')\n",
    "        print(\"Success! Your data is now in PostgreSQL.\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588408f6-8951-41ff-bd20-37cb5692404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sal\n",
    "import urllib.parse\n",
    "\n",
    "# 1. Re-initialize the engine\n",
    "user = 'postgres'\n",
    "password = 'admin123' \n",
    "database = 'order_database' \n",
    "\n",
    "# Secure the password for the connection string\n",
    "safe_password = urllib.parse.quote_plus(password)\n",
    "engine = sal.create_engine(f'postgresql://{user}:{safe_password}@localhost:5432/{database}')\n",
    "\n",
    "# 2. Open a fresh connection and append data\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # We use 'append' because you just created the table manually\n",
    "        df.to_sql('df_orders', con=conn, index=False, if_exists='append')\n",
    "        print(\"Success! All data has been loaded into your new table.\")\n",
    "except Exception as e:\n",
    "    print(f\"Loading failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36161bae-3d28-4164-8e8b-bc7ac2f1cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad8eab-e017-4b52-a8a7-76f0209540ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
